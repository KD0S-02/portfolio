---
title: "Building a P2P File Transfer Tool from Scratch - Part 1: The Easy Local Part"
date: "2025-08-12"
excerpt: "Summer break networking adventures with TCP, binary protocols, and the harsh reality of NAT traversal"
tags: ["go", "networking", "tcp", "p2p", "binary-protocol", "learning"]
series: "kdtransfer"
part: 1
author: "Krishnadas Nair"
readTime: "8 min read"
---

# Building a P2P File Transfer Tool from Scratch - Part 1: The "Easy" Local Part

## Prologue

Summer break. Just finished Professor Alden Jackson's networking course at Northeastern. He was incredibly passionate about networking, and I guess it kinda rubbed off on me.

So I wanted to put my half-cooked theoretical knowledge on network protocols and sockets into actual practice. What better way than building a file transfer app?

The idea was simple: connect two computers and just send files as bytes. Very easy. 

It was all sunshine and rainbows until two weeks later I'm in the trenches, going down rabbit hole after rabbit hole on hole punching, WebRTC, STUN servers... just to send a single file over the internet.

"Let me walk you through how 'just send bytes' became a crash course in why the internet hates direct connections."

## TCP: Just a Chill, Reliable Guy

Before we get into all the "fun stuff," let's talk about my guy TCP. He's very chill, very reliable. Why TCP?

- **Reliability**: Packets arrive or you know they didn't
- **Ordering**: Chunks arrive in the right sequence  
- **Flow control**: TCP won't overwhelm the receiver
- **Simplicity**: Just read and write bytes

So all I gotta worry about is sending and receiving bytes. Don't have to worry about my packets not making it or coming in all jumbled up.

Think of TCP like this: the receiver sets up a special mailbox on a certain port and keeps checking it for new mail. 
Before sending anything, the sender first calls ahead to say “I’m about to send you some letters” (the handshake). 
Each letter is numbered, so they always arrive in order. If a letter goes missing, the sender just sends it again.

Just a simple example:
```go
// Sender side
conn := tcp.Dial(address)
message := "hello"
conn.Write([]byte(message))

// Receiver side
conn := tcp.Listen(address)
buffer := make([]byte, 256)
for {
   n, err := conn.Read(buffer)
   // Now what? Is this a complete message?
}
```

It's a common misconception that you get neat packets on a TCP connection. Instead of defined borders, 
imagine it as a pipe between sender and receiver where data flows as a stream. Sender writes to it, receiver reads from it.
This is where it gets tricky: how do you define borders for messages? Look at the above code, 
how can you decide on a good buffer size when payload sizes for messages can vary wildly?
This is where my binary protocol comes in clutch.


## Binary Protocols: Parting the TCP stream

Like Moses, but instead of splitting seas, my protocol helps split messages in the TCP stream. HTTP and JSON would work, sure, 
but where's the learning in that? I wanted to design my own protocol from scratch.

Plus, after studying how TCP, IP, and Ethernet headers work, I was convinced that binary protocols were just... cooler. 
More efficient, more "real systems programming."

The design was dead simple:

```
[1 byte: opcode][4 bytes: payload length][payload...]
```

Five bytes of overhead per message. Compare that to HTTP headers ("GET /api/upload HTTP/1.1\r\nContent-Type: application/json\r\n...") 
and you can see why I was excited about this approach.

**How does it help eliminate partial reads?** 

Now i know exactly what to look for, always check for a 5 byte header first. The 4-byte length field is key here, 
as it tells me how much of the stream I should read into my buffer to get the payload. 
This eliminates the need for complex buffering logic to handle incomplete data.

Simple but gets the job done. The first byte gives me additional info on what type of message this is.


For the local file transfer, I only needed three simple opcodes:

```go
FILE_TRANSFER_START byte = 0x07  // "Hey, incoming file with this info"
FILE_TRANSFER_DATA  byte = 0x08  // "Here's a chunk of that file"  
FILE_TRANSFER_END   byte = 0x09  // "File complete, we're done"
```

But being the optimistic engineer I am, I designed the protocol with room to grow. The full protocol spec ended up looking like this:

```go
const (
    SERVER_HELLO        byte = 0x01
    SERVER_ACK          byte = 0x02
    PEER_INFO_LOOKUP    byte = 0x03
    PEER_LOOKUP_ACK     byte = 0x04
    BYE                 byte = 0x05
    ERROR               byte = 0x06
    FILE_TRANSFER_START byte = 0x07
    FILE_TRANSFER_DATA  byte = 0x08
    FILE_TRANSFER_END   byte = 0x09
    PEER_INFO_FORWARD   byte = 0x0A
)
```

Those extra opcodes? That's where the adventure gets interesting. The peer discovery ops (0x03-0x04) 
and WebRTC signaling (0x0A) came later when I realized local transfers were just the beginning. 
But we're getting ahead of ourselves. That's Parts 2 and 3 material.

## Chunking: Because RAM is Not Infinite

This came naturally to me since most of my undergrad coding was in C and C++, where memory management is everything. 
The naive approach would be:

```go
// DON'T DO THIS
data, err := os.ReadFile("huge_movie_4k.mp4") // Load entire 4GB file
conn.Write(data) // RIP your RAM
```

If that file is larger than your available RAM, your PC won't find it very funny.
But chunking solves more than just memory issues. 

Breaking files into pieces gives you:

- **Streaming to disk**: Write chunks directly as they arrive, no buffering the whole file
- **bandwidth control**: Send chunks at a controlled rate, don't flood the network
- **future-proofing**: Easy to add resume capability later as chunks become natural checkpoints
- **error isolation**: If one chunk fails, you only retry that piece, not the entire file

The trade-off? Chunk size matters. Too small = more protocol overhead. Too large = more memory usage and bigger chunks to retry on failure. 
I settled on **512KB** after testing as it strikes a good balance between efficiency and resource usage.
(Note: WebRTC will need different chunk sizes, but that's Part 3 material.)

## Session-Based Discovery: No More IP Address Sharing

Nobody likes sharing IP addresses, I get it, and it can be confusing to some. Plus, a multicast approach would mean random requests that nobody wants, so I had to channel my inner tinfoil hat energy for a simple but efficient approach.

Here's how it works:
1. **Receiver starts up** - automatically discovers all network interfaces (WiFi, ethernet, etc.)
2. **Registers with signaling server** - gets back a simple 8-character code like `XK7M2P9Q`
3. **Sender uses the code** - fetches all the receiver's network addresses
4. **Connection racing** - sender tries connecting to all addresses simultaneously, fastest one wins

The 8-character code acts as a temporary "key" and only peers who have that code can send you stuff. 
It's shared out-of-band (text, Slack, carrier pigeon, whatever). No random strangers blasting files at your machine.
The signaling server only handles address discovery. The actual meat and bones, i.e. the file data, 
flows directly peer-to-peer via TCP. Very clean, very cool.

## Maiden Voyage - The Moment of Truth

After starting the signaling server and getting the receiver connected with session ID `gtdpt675`, time for the actual transfer.

On the sender:
```bash
$ go run cmd/client/main.go send --peer gtdpt675 --file cool_video.mp4
Peer Info found for gtdpt675
2025/08/12 14:42:34 Sending file: cool_video.mp4 (ID: 484867138, Size: 111035154 bytes, Chunks: 212)
2025/08/12 14:42:41 Transfer 484867138: uploaded successfully in 6.6386689s
```

And on the receiver side:
```bash
$ go run ../cmd/client/main.go recv
No .env file found, using defaults
2025/08/12 14:42:30 Current ID: gtdpt675
Type 'disconnect' to exit
2025/08/12 14:42:34 Receiving file: cool_video.mp4 (ID: 484867138, Size: 111035154 bytes, Chunks: 212)
2025/08/12 14:42:41 Transfer 484867138: received successfully in 6.6397975s
```

*It worked.* My Frankenstein protocol actually transferred a 106MB video in 6.6 seconds. 
That's roughly 16 MB/s, pretty solid for a from-scratch protocol where the file I/O and network 
send/read are all single-threaded as of now (please don't judge). I do use goroutines for connection racing and server handling, 
and for listening and handling connections on the receiver side for concurrent file transfers, 
but the core transfer pipeline is sequential mainly to avoid chunk order complexity. 
Future optimization would be making it concurrent/multi-threaded to make it blazingly fast.

## Error Handling: Because Murphy's Law is Universal

Even in the "easy" local case, things can go wrong:
- Files might not exist
- Disk might be full  
- Network connections drop
- Permission issues

The key is failing gracefully:

```go
file, err := os.Create(filename)
if err != nil {
    return fmt.Errorf("failed to create file: %w", err)
}
defer file.Close() // Always clean up

_, err = file.Write(chunkData)
if err != nil {
    return fmt.Errorf("failed to write chunk: %w", err)
}
```

Go's explicit error handling might be verbose, but it forces you to think about what can go wrong. And trust me, everything that can go wrong, will.

## The Reality Check

Drunk on success, I decided to test it with my friend at college. He's on campus WiFi, I'm on my home network. 
I sent him the code, we both fired it up fingers crossed, and...

Nothing. Connection refused. Timeouts.

I even tried his public IP directly. Still failed. Reality hit: NAT routers don't know which device behind them should receive 
incoming connections.

I knew I'd hit this wall, but it still hurt. When you're behind NAT, routers only track outbound connections you started. 
Random incoming connections just get dropped as the router has no clue if it's for your laptop, your roommate's phone, or what.

This is where I learned the painful difference between LAN and WAN. My beautiful TCP solution that worked perfectly 
at home suddenly felt like a toy against the real internet.

The harsh reality: NAT, port forwarding, and the challenge of direct connections when both peers are behind routers.
"P2P" and "across the internet" are completely different problems.

## What's Next?

So that's where Part 1 ends. With a working local file transfer tool that automatically discovers network interfaces and 
uses session-based peer discovery. The system works great on local networks, but there's still more to build.

**Coming in Part 2:** Adding end-to-end encryption with out-of-band passphrases, so the signaling server never sees your actual data. 
Just an encrypted blob. The same passphrase will help encrypt the direct transfer too.

**Part 3 will tackle the real challenge:** WebRTC integration with Pion library, STUN servers for public IP discovery, 
and connection racing between TCP (LAN) and WebRTC data channels (WAN). We are bringing out the big guns to fight the internet.

The complete code for the local version is [on my GitHub](https://github.com/KD0S-02/KDTransfer). 
The session-based discovery and automatic network interface detection already make it pretty useful for LAN transfers.

---
     
*This is Part 1 of my series on building a P2P file transfer tool. 
I'm documenting my learning journey as a first-year CS grad student at Northeastern. These are just my insights and experiments, 
I'm definitely not an expert! Follow along for the encryption deep dive, WebRTC adventures, 
and probably some spectacular failures along the way.*

**Next up: Part 2 - Adding End-to-End Encryption (And Why Passphrases Matter)**